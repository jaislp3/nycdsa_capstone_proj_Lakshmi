{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "hkong = spark.table(\"hkongpercent_1_ord_currency_35acb_csv\")\n",
    "display(hkong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "X = hkong.columns[1:311]\n",
    "assembler = VectorAssembler(inputCols=X, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Create initial LogisticRegression model\n",
    "lr = LogisticRegression()\n",
    "# Import the evaluation submodule\n",
    "import pyspark.ml.evaluation as evals\n",
    "\n",
    "# Create a BinaryClassificationEvaluator\n",
    "evaluator = evals.BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
    "# Import the tuning submodule\n",
    "import pyspark.ml.tuning as tune\n",
    "import numpy as np\n",
    "\n",
    "# Create the parameter grid\n",
    "grid = tune.ParamGridBuilder()\n",
    "\n",
    "# Add the hyperparameter\n",
    "grid = grid.addGrid(lr.regParam, np.arange(0, .1, .01))\n",
    "grid = grid.addGrid(lr.elasticNetParam, [0, 1])\n",
    "\n",
    "# Build the grid\n",
    "grid = grid.build()\n",
    "\n",
    "cv = tune.CrossValidator(estimator=lr,\n",
    "                         estimatorParamMaps=grid,\n",
    "                         evaluator=evaluator\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "scores=[]\n",
    "target = hkong.columns[311:]\n",
    "for i in target:\n",
    "  #print i\n",
    "  data = hkong.select(hkong.columns[:311] + [i])\n",
    "  new_data = data.select(*[col(s).alias('label') if s ==i  else s for s in data.columns])\n",
    "  new_data  = assembler.transform(new_data)  \n",
    "  (training, test) = new_data.randomSplit([0.7, 0.3], seed = 100)  \n",
    "  models = cv.fit(training)  \n",
    "  best_lr = models.bestModel\n",
    "  print i\n",
    "  print(best_lr)    \n",
    "  test_results = best_lr.transform(test)\n",
    "  print (evaluator.evaluate(test_results))\n",
    "  scores.append(evaluator.evaluate(test_results))\n",
    "\n",
    "print(scores)\n",
    "#print training.count()\n",
    "#print test.count()\n",
    "#display(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not needed\n",
    "from pyspark.sql.functions import col\n",
    "new_data = data.select(*[col(s).alias('label') if s =='Target_0'  else s for s in data.columns])\n",
    "display(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not needed\n",
    "new_data  =assembler.transform(new_data)\n",
    "### Randomly split data into training and test sets. set seed for reproducibility\n",
    "(training, test) = new_data.randomSplit([0.7, 0.3], seed = 100)\n",
    "print training.count()\n",
    "print test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Not needed\n",
    "# Fit cross validation models\n",
    "models = cv.fit(training)\n",
    "\n",
    "# Extract the best model\n",
    "best_lr = models.bestModel\n",
    "\n",
    "# Print best_lr\n",
    "print(best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not needed\n",
    "# Use the model to predict the test set\n",
    "test_results = best_lr.transform(test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "print(evaluator.evaluate(test_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "name": "hangseng_all",
  "notebookId": 1273668252982862
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
